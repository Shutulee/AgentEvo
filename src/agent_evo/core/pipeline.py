"""Pipeline ç¼–æ’å™¨"""

import asyncio
from datetime import datetime
from pathlib import Path
from typing import Optional

from rich.console import Console

from agent_evo.models import Config, EvalReport, OptimizationResult
from agent_evo.core.generator import Generator
from agent_evo.core.evaluator import Evaluator
from agent_evo.core.optimizer import Optimizer
from agent_evo.integrations.git import GitIntegration


console = Console()


class PipelineResult:
    """Pipeline æ‰§è¡Œç»“æœ"""
    
    def __init__(
        self,
        eval_report: EvalReport,
        optimization: Optional[OptimizationResult] = None,
        pr_url: Optional[str] = None
    ):
        self.eval_report = eval_report
        self.optimization = optimization
        self.pr_url = pr_url
    
    @property
    def success(self) -> bool:
        """æ˜¯å¦æˆåŠŸï¼ˆé€šè¿‡ç‡è¾¾æ ‡æˆ–ä¼˜åŒ–æˆåŠŸï¼‰"""
        if self.optimization and self.optimization.success:
            return True
        return self.eval_report.pass_rate >= 0.95


class Pipeline:
    """AgentEvo æ ¸å¿ƒ Pipeline"""
    
    def __init__(self, config: Config, project_dir: Optional[str] = None):
        self.config = config
        self.project_dir = Path(project_dir) if project_dir else Path.cwd()
        
        self.generator = Generator(config, self.project_dir)
        self.evaluator = Evaluator(config)
        self.optimizer = Optimizer(config, self.project_dir)
        self.git = GitIntegration(config.git, self.project_dir) if config.git.enabled else None
    
    async def run(
        self,
        auto_fix: bool = False,
        create_pr: bool = False,
        tags: Optional[list[str]] = None,
        dry_run: bool = False
    ) -> PipelineResult:
        """
        è¿è¡Œå®Œæ•´æµç¨‹
        
        Args:
            auto_fix: æ˜¯å¦è‡ªåŠ¨ä¿®å¤å¤±è´¥ç”¨ä¾‹
            create_pr: æ˜¯å¦åˆ›å»º PR
            tags: åªè¿è¡ŒæŒ‡å®š tag çš„ç”¨ä¾‹
            dry_run: é¢„è§ˆæ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶
            
        Returns:
            PipelineResult
        """
        console.print("\n[bold blue]ğŸš€ AgentEvo Pipeline å¯åŠ¨[/bold blue]\n")
        
        # 1. åŠ è½½æµ‹è¯•ç”¨ä¾‹
        test_cases = self.generator.load_test_cases(tags=tags)
        console.print(f"ğŸ“‹ åŠ è½½äº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
        
        # 2. æ‰§è¡Œæµ‹è¯•
        console.print("\n[bold]â–¶ æ‰§è¡Œæµ‹è¯•...[/bold]")
        started_at = datetime.now()
        results = await self.generator.run_all(test_cases)
        
        # 3. è¯„åˆ¤
        console.print("\n[bold]â–¶ è¯„åˆ¤ç»“æœ...[/bold]")
        eval_report = await self.evaluator.evaluate_all(results)
        eval_report.started_at = started_at
        eval_report.finished_at = datetime.now()
        eval_report.duration_seconds = (eval_report.finished_at - started_at).total_seconds()
        
        self._print_eval_summary(eval_report)
        
        optimization_result = None
        pr_url = None
        
        # 4. å¦‚æœæœ‰å¤±è´¥ä¸”å¼€å¯è‡ªåŠ¨ä¿®å¤
        if auto_fix and eval_report.failed > 0:
            console.print("\n[bold]â–¶ è¯Šæ–­å¤±è´¥ç”¨ä¾‹...[/bold]")
            
            failed_results = eval_report.get_failed_results()
            diagnoses = await self.evaluator.diagnose_all(failed_results)
            
            # ç­›é€‰å¯ä¿®å¤çš„ï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰
            fixable = [
                d for d in diagnoses 
                if d.auto_fixable and d.confidence >= self.config.diagnosis.confidence_threshold
            ]
            
            if fixable:
                console.print(f"ğŸ”§ å‘ç° {len(fixable)} ä¸ªå¯è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜")
                
                if dry_run:
                    console.print("\n[yellow]âš  Dry-run æ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶[/yellow]")
                    for d in fixable:
                        console.print(f"  - {d.case_id}: {d.category.value} ({d.confidence:.0%})")
                        console.print(f"    å»ºè®®: {d.suggestion}")
                else:
                    console.print("\n[bold]â–¶ ä¼˜åŒ–æç¤ºè¯...[/bold]")
                    optimization_result = await self.optimizer.optimize(
                        diagnoses=fixable,
                        test_cases=test_cases
                    )
                    
                    if optimization_result.success:
                        console.print(f"[green]âœ… ä¼˜åŒ–æˆåŠŸï¼è¿­ä»£ {optimization_result.iterations} æ¬¡[/green]")
                        
                        # 5. åˆ›å»º PR
                        if create_pr and self.git:
                            console.print("\n[bold]â–¶ åˆ›å»º PR...[/bold]")
                            pr_url = await self.git.create_pr(
                                title=f"[AgentEvo] è‡ªåŠ¨ä¼˜åŒ–: ä¿®å¤ {len(fixable)} ä¸ªå¤±è´¥ç”¨ä¾‹",
                                body=self._generate_pr_body(eval_report, optimization_result, fixable),
                                changes=[(self.config.agent.prompt_file, optimization_result.optimized_prompt)]
                            )
                            console.print(f"[green]âœ… PR å·²åˆ›å»º: {pr_url}[/green]")
                    else:
                        console.print(f"[red]âŒ ä¼˜åŒ–æœªèƒ½å®Œå…¨è§£å†³é—®é¢˜[/red]")
            else:
                console.print("[yellow]âš  æ²¡æœ‰å¯è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜ï¼ˆç½®ä¿¡åº¦ä¸è¶³æˆ–å½’å› ç±»å‹ä¸æ”¯æŒï¼‰[/yellow]")
        
        return PipelineResult(
            eval_report=eval_report,
            optimization=optimization_result,
            pr_url=pr_url
        )
    
    async def eval_only(self, tags: Optional[list[str]] = None) -> EvalReport:
        """åªè¿è¡Œè¯„æµ‹ï¼Œä¸ä¼˜åŒ–"""
        test_cases = self.generator.load_test_cases(tags=tags)
        results = await self.generator.run_all(test_cases)
        return await self.evaluator.evaluate_all(results)
    
    def _print_eval_summary(self, report: EvalReport) -> None:
        """æ‰“å°è¯„æµ‹æ‘˜è¦"""
        status_icon = "âœ…" if report.pass_rate >= 0.95 else "âŒ" if report.pass_rate < 0.7 else "âš ï¸"
        
        console.print(f"\n{status_icon} [bold]è¯„æµ‹ç»“æœ[/bold]")
        console.print(f"   æ€»è®¡: {report.total}  é€šè¿‡: {report.passed}  å¤±è´¥: {report.failed}  é”™è¯¯: {report.error}")
        console.print(f"   é€šè¿‡ç‡: {report.pass_rate:.1%}")
        console.print(f"   è€—æ—¶: {report.duration_seconds:.2f}s")
        
        if report.failed > 0:
            console.print("\n[bold red]å¤±è´¥ç”¨ä¾‹:[/bold red]")
            for r in report.get_failed_results()[:5]:  # æœ€å¤šæ˜¾ç¤º 5 ä¸ª
                console.print(f"   - {r.case_id}: {r.summary[:50]}...")
    
    def _generate_pr_body(self, report: EvalReport, opt_result: OptimizationResult, diagnoses) -> str:
        """ç”Ÿæˆ PR æè¿°"""
        body = f"""## AgentEvo è‡ªåŠ¨ä¼˜åŒ–æŠ¥å‘Š

### ğŸ“Š è¯„æµ‹ç»“æœ
- æ€»ç”¨ä¾‹: {report.total}
- é€šè¿‡: {report.passed}
- å¤±è´¥: {report.failed}
- åŸå§‹é€šè¿‡ç‡: {report.pass_rate:.1%}

### ğŸ”§ ä¿®å¤å†…å®¹
"""
        for d in diagnoses:
            body += f"- **{d.case_id}**: {d.category.value}\n"
            body += f"  - åŸå› : {d.root_cause}\n"
            body += f"  - ç½®ä¿¡åº¦: {d.confidence:.0%}\n"
        
        if opt_result.regression_pass_rate:
            body += f"\n### âœ… å›å½’æµ‹è¯•\né€šè¿‡ç‡: {opt_result.regression_pass_rate:.1%}\n"
        
        body += "\n---\n*ç”± AgentEvo è‡ªåŠ¨ç”Ÿæˆ*"
        return body
